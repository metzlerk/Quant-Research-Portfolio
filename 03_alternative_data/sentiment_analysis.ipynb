{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "14f7f155",
   "metadata": {},
   "source": [
    "# Alternative Data Integration for Quantitative Finance\n",
    "\n",
    "**Author**: Kevin J. Metzler  \n",
    "**Date**: August 6, 2025\n",
    "\n",
    "This notebook demonstrates the integration of alternative data sources with traditional market data for enhanced signal generation in quantitative trading strategies. We explore how news sentiment, social media data, and other non-traditional data sources can provide additional alpha when properly incorporated into quantitative models."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37c63f38",
   "metadata": {},
   "source": [
    "## 1. Introduction to Alternative Data in Finance\n",
    "\n",
    "Alternative data refers to non-traditional data sources that can provide insights into financial markets beyond standard market data. These include:\n",
    "\n",
    "- **News and Social Media**: Sentiment analysis from news articles, tweets, and forum discussions\n",
    "- **Satellite Imagery**: Analysis of parking lots, shipping activity, and agricultural fields\n",
    "- **Web Traffic**: Consumer interest measured through website visits and app usage\n",
    "- **Credit Card Transactions**: Consumer spending patterns and trends\n",
    "- **Geolocation Data**: Foot traffic at retail locations and other venues\n",
    "\n",
    "In this notebook, we'll focus on implementing news sentiment analysis and its integration with traditional market data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "360f389f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import sys\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from datetime import datetime, timedelta\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Add parent directory to path\n",
    "sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath('__file__'))))\n",
    "\n",
    "# Import our alternative data module\n",
    "from alternative_data import AlternativeDataIntegration, AlternativeDataConfig, NewsSentimentAnalyzer\n",
    "\n",
    "# Configure plots\n",
    "sns.set_style('whitegrid')\n",
    "plt.rcParams['figure.figsize'] = (12, 6)\n",
    "plt.rcParams['axes.grid'] = True\n",
    "\n",
    "# Load environment variables for API keys\n",
    "load_dotenv()\n",
    "\n",
    "# Check if API keys are available\n",
    "news_api_key = os.getenv(\"NEWS_API_KEY\")\n",
    "if not news_api_key:\n",
    "    print(\"WARNING: NEWS_API_KEY not found. Using simulated data.\")\n",
    "    using_simulated_data = True\n",
    "else:\n",
    "    using_simulated_data = False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79950ec3",
   "metadata": {},
   "source": [
    "## 2. Fetching Market Data\n",
    "\n",
    "Let's start by fetching market data for analysis. We'll use the `yfinance` library to obtain price data for selected securities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8eced1ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "import yfinance as yf\n",
    "\n",
    "# Define the securities we want to analyze\n",
    "tickers = ['AAPL', 'MSFT', 'GOOGL', 'AMZN', 'NVDA']\n",
    "\n",
    "# Define time period\n",
    "start_date = '2023-01-01'\n",
    "end_date = '2023-12-31'\n",
    "\n",
    "# Fetch market data\n",
    "market_data = {}\n",
    "\n",
    "for ticker in tickers:\n",
    "    try:\n",
    "        data = yf.download(ticker, start=start_date, end=end_date, progress=False)\n",
    "        \n",
    "        # Remove the multi-index structure for simpler processing\n",
    "        if isinstance(data.columns, pd.MultiIndex):\n",
    "            data.columns = [col[0] for col in data.columns]\n",
    "        \n",
    "        # Calculate returns\n",
    "        data['return'] = data['Close'].pct_change()\n",
    "        data['log_return'] = np.log(data['Close'] / data['Close'].shift(1))\n",
    "        \n",
    "        # Calculate volatility\n",
    "        data['volatility_20d'] = data['return'].rolling(20).std() * np.sqrt(252)\n",
    "        \n",
    "        market_data[ticker] = data\n",
    "        print(f\"Fetched {len(data)} days of data for {ticker}\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error fetching data for {ticker}: {e}\")\n",
    "\n",
    "# Show sample of the data\n",
    "if market_data:\n",
    "    sample_ticker = tickers[0]\n",
    "    print(f\"\\nSample data for {sample_ticker}:\")\n",
    "    print(market_data[sample_ticker].head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11390bc1",
   "metadata": {},
   "source": [
    "## 3. News Sentiment Analysis\n",
    "\n",
    "Now we'll implement news sentiment analysis for our selected securities using the NewsAPI. If the API key is not available, we'll generate simulated sentiment data for demonstration purposes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "786b7aeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the alternative data integrator\n",
    "alt_data = AlternativeDataIntegration(data_dir=\"../data/alternative\")\n",
    "\n",
    "# Function to create simulated sentiment data if needed\n",
    "def create_simulated_sentiment_data(ticker, data):\n",
    "    \"\"\"\n",
    "    Create simulated sentiment data for demonstration purposes when API keys are not available.\n",
    "    This uses price momentum and adds random noise to simulate sentiment.\n",
    "    \"\"\"\n",
    "    # Calculate price momentum\n",
    "    price_momentum = data['Close'].pct_change(5).fillna(0)\n",
    "    \n",
    "    # Create sentiment with momentum and noise\n",
    "    np.random.seed(42)  # For reproducibility\n",
    "    noise = pd.Series(np.random.normal(0, 0.005, len(data)), index=data.index)\n",
    "    sentiment = price_momentum + noise\n",
    "    \n",
    "    # Scale to sentiment range (-1 to 1)\n",
    "    sentiment = np.tanh(sentiment * 10)\n",
    "    \n",
    "    # Create sentiment DataFrame\n",
    "    sentiment_df = pd.DataFrame({\n",
    "        'compound': sentiment,\n",
    "        'positive': (sentiment + 1) / 2,  # Scale to 0-1\n",
    "        'negative': (1 - sentiment) / 2,  # Scale to 0-1\n",
    "    }, index=data.index)\n",
    "    \n",
    "    # Add rolling metrics\n",
    "    window = 30  # days\n",
    "    sentiment_df[f'compound_{window}d_avg'] = sentiment_df['compound'].rolling(window).mean()\n",
    "    sentiment_df[f'positive_{window}d_avg'] = sentiment_df['positive'].rolling(window).mean()\n",
    "    sentiment_df[f'negative_{window}d_avg'] = sentiment_df['negative'].rolling(window).mean()\n",
    "    sentiment_df['sentiment_momentum'] = sentiment_df[f'compound_{window}d_avg'].diff()\n",
    "    \n",
    "    # Create topic data (simulated)\n",
    "    for i in range(5):  # 5 simulated topics\n",
    "        topic_noise = pd.Series(np.random.normal(0, 0.1, len(data)), index=data.index)\n",
    "        sentiment_df[f'topic_{i}'] = topic_noise + sentiment_df['compound'] * np.random.uniform(0.5, 1.5)\n",
    "    \n",
    "    return sentiment_df\n",
    "\n",
    "# Process each ticker\n",
    "enhanced_data = {}\n",
    "\n",
    "for ticker in tickers:\n",
    "    if ticker not in market_data:\n",
    "        continue\n",
    "        \n",
    "    print(f\"\\nProcessing alternative data for {ticker}...\")\n",
    "    \n",
    "    if using_simulated_data:\n",
    "        # Use simulated data\n",
    "        sentiment_data = create_simulated_sentiment_data(ticker, market_data[ticker])\n",
    "        enhanced_data[ticker] = pd.concat([market_data[ticker], sentiment_data], axis=1)\n",
    "        print(f\"  Created simulated sentiment data for {ticker}\")\n",
    "    else:\n",
    "        # Use real data from NewsAPI\n",
    "        enhanced_data[ticker] = alt_data.integrate_all_sources(\n",
    "            ticker, \n",
    "            market_data[ticker], \n",
    "            start_date, \n",
    "            end_date\n",
    "        )\n",
    "        print(f\"  Integrated alternative data for {ticker}\")\n",
    "\n",
    "# Show sample of enhanced data\n",
    "if enhanced_data:\n",
    "    sample_ticker = tickers[0]\n",
    "    print(f\"\\nSample enhanced data for {sample_ticker}:\")\n",
    "    # Show just a few columns to avoid cluttering the output\n",
    "    display_cols = ['Close', 'return', 'compound', 'compound_30d_avg', 'sentiment_momentum']\n",
    "    display_cols = [col for col in display_cols if col in enhanced_data[sample_ticker].columns]\n",
    "    print(enhanced_data[sample_ticker][display_cols].head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37e92dc4",
   "metadata": {},
   "source": [
    "## 4. Visualizing Sentiment and Price Relationships\n",
    "\n",
    "Let's visualize the relationship between news sentiment and price movements to better understand how sentiment might influence or reflect market behavior."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "080fccf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_sentiment_price_relationship(ticker, data):\n",
    "    \"\"\"Plot the relationship between sentiment and price for a given ticker.\"\"\"\n",
    "    if 'compound_30d_avg' not in data.columns or 'Close' not in data.columns:\n",
    "        print(f\"Required columns not found for {ticker}\")\n",
    "        return\n",
    "    \n",
    "    # Create figure with two y-axes\n",
    "    fig, ax1 = plt.subplots(figsize=(14, 8))\n",
    "    ax2 = ax1.twinx()\n",
    "    \n",
    "    # Plot price on primary y-axis\n",
    "    ax1.plot(data.index, data['Close'], 'b-', label=f\"{ticker} Price\")\n",
    "    ax1.set_xlabel('Date')\n",
    "    ax1.set_ylabel('Price ($)', color='b')\n",
    "    ax1.tick_params(axis='y', labelcolor='b')\n",
    "    \n",
    "    # Plot sentiment on secondary y-axis\n",
    "    ax2.plot(data.index, data['compound_30d_avg'], 'g-', label='30-day Sentiment')\n",
    "    ax2.set_ylabel('Sentiment Score', color='g')\n",
    "    ax2.tick_params(axis='y', labelcolor='g')\n",
    "    ax2.axhline(y=0, color='r', linestyle='--', alpha=0.3)\n",
    "    \n",
    "    # Add a title with correlation coefficient\n",
    "    corr = data[['Close', 'compound_30d_avg']].corr().iloc[0, 1]\n",
    "    plt.title(f\"{ticker}: Price vs. News Sentiment (Correlation: {corr:.3f})\")\n",
    "    \n",
    "    # Add legend\n",
    "    lines1, labels1 = ax1.get_legend_handles_labels()\n",
    "    lines2, labels2 = ax2.get_legend_handles_labels()\n",
    "    ax1.legend(lines1 + lines2, labels1 + labels2, loc='upper left')\n",
    "    \n",
    "    plt.grid(True, alpha=0.3)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # Return the correlation for further analysis\n",
    "    return corr\n",
    "\n",
    "# Plot for each ticker\n",
    "correlations = {}\n",
    "for ticker in enhanced_data:\n",
    "    print(f\"\\nAnalyzing sentiment-price relationship for {ticker}\")\n",
    "    corr = plot_sentiment_price_relationship(ticker, enhanced_data[ticker])\n",
    "    correlations[ticker] = corr\n",
    "\n",
    "# Compare correlations across tickers\n",
    "if correlations:\n",
    "    corr_df = pd.DataFrame(list(correlations.items()), columns=['Ticker', 'Correlation'])\n",
    "    corr_df = corr_df.sort_values('Correlation', ascending=False).reset_index(drop=True)\n",
    "    \n",
    "    plt.figure(figsize=(10, 6))\n",
    "    sns.barplot(x='Ticker', y='Correlation', data=corr_df)\n",
    "    plt.title('Sentiment-Price Correlation by Ticker')\n",
    "    plt.axhline(y=0, color='r', linestyle='--', alpha=0.3)\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47fddc31",
   "metadata": {},
   "source": [
    "## 5. Creating a Sentiment-Enhanced Trading Signal\n",
    "\n",
    "Now, let's develop a simple trading strategy that incorporates sentiment data along with traditional price signals."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06da4f8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_sentiment_enhanced_signals(data, sentiment_threshold=0.1, momentum_lookback=20):\n",
    "    \"\"\"Generate trading signals based on price momentum and sentiment.\"\"\"\n",
    "    signals = pd.DataFrame(index=data.index)\n",
    "    \n",
    "    # Calculate price momentum\n",
    "    signals['price_momentum'] = data['Close'].pct_change(momentum_lookback)\n",
    "    \n",
    "    # Get sentiment signals\n",
    "    if 'compound_30d_avg' in data.columns:\n",
    "        signals['sentiment'] = data['compound_30d_avg']\n",
    "    else:\n",
    "        signals['sentiment'] = 0  # Neutral if no sentiment data\n",
    "    \n",
    "    # Generate base signals (price momentum only)\n",
    "    signals['base_signal'] = 0\n",
    "    signals.loc[signals['price_momentum'] > 0.05, 'base_signal'] = 1  # Long\n",
    "    signals.loc[signals['price_momentum'] < -0.05, 'base_signal'] = -1  # Short\n",
    "    \n",
    "    # Generate enhanced signals (price momentum + sentiment)\n",
    "    signals['enhanced_signal'] = signals['base_signal'].copy()\n",
    "    \n",
    "    # Amplify signals when sentiment agrees with momentum\n",
    "    signals.loc[(signals['base_signal'] > 0) & (signals['sentiment'] > sentiment_threshold), 'enhanced_signal'] = 2\n",
    "    signals.loc[(signals['base_signal'] < 0) & (signals['sentiment'] < -sentiment_threshold), 'enhanced_signal'] = -2\n",
    "    \n",
    "    # Reduce signals when sentiment contradicts momentum\n",
    "    signals.loc[(signals['base_signal'] > 0) & (signals['sentiment'] < -sentiment_threshold), 'enhanced_signal'] = 0\n",
    "    signals.loc[(signals['base_signal'] < 0) & (signals['sentiment'] > sentiment_threshold), 'enhanced_signal'] = 0\n",
    "    \n",
    "    return signals\n",
    "\n",
    "def backtest_strategy(data, signals, initial_capital=10000, transaction_cost=0.001):\n",
    "    \"\"\"Simple backtesting of a trading strategy.\"\"\"\n",
    "    # Initialize portfolio and positions\n",
    "    portfolio = pd.DataFrame(index=signals.index)\n",
    "    portfolio['holdings'] = 0.0\n",
    "    portfolio['cash'] = initial_capital\n",
    "    portfolio['total'] = initial_capital\n",
    "    portfolio['returns'] = 0.0\n",
    "    portfolio['signal'] = signals\n",
    "    portfolio['position'] = 0\n",
    "    \n",
    "    # Position sizing - simple implementation\n",
    "    position_size = initial_capital * 0.95  # Use 95% of capital\n",
    "    \n",
    "    for i in range(1, len(portfolio)):\n",
    "        # Get previous positions and current price\n",
    "        prev_position = portfolio['position'].iloc[i-1]\n",
    "        prev_holdings = portfolio['holdings'].iloc[i-1]\n",
    "        prev_cash = portfolio['cash'].iloc[i-1]\n",
    "        price = data['Close'].iloc[i]\n",
    "        prev_price = data['Close'].iloc[i-1]\n",
    "        \n",
    "        # Calculate position change based on signal\n",
    "        signal = signals.iloc[i]\n",
    "        new_position = signal\n",
    "        \n",
    "        # If position changes, execute trade\n",
    "        if new_position != prev_position:\n",
    "            # Close out previous position\n",
    "            if prev_position != 0:\n",
    "                # Sell position\n",
    "                trade_value = prev_holdings * (1 - transaction_cost)\n",
    "                portfolio['cash'].iloc[i] = prev_cash + trade_value\n",
    "                portfolio['holdings'].iloc[i] = 0\n",
    "            else:\n",
    "                portfolio['cash'].iloc[i] = prev_cash\n",
    "                portfolio['holdings'].iloc[i] = 0\n",
    "            \n",
    "            # Open new position if applicable\n",
    "            if new_position != 0:\n",
    "                # Calculate number of shares based on signal strength\n",
    "                signal_strength = abs(new_position)\n",
    "                trade_value = position_size * signal_strength / 2\n",
    "                \n",
    "                # Adjust for direction (long/short)\n",
    "                if new_position > 0:  # Long position\n",
    "                    shares = trade_value / price\n",
    "                    cost = shares * price * (1 + transaction_cost)\n",
    "                    portfolio['cash'].iloc[i] -= cost\n",
    "                    portfolio['holdings'].iloc[i] = shares * price\n",
    "                else:  # Short position\n",
    "                    shares = trade_value / price\n",
    "                    proceeds = shares * price * (1 - transaction_cost)\n",
    "                    portfolio['cash'].iloc[i] += proceeds\n",
    "                    portfolio['holdings'].iloc[i] = -shares * price\n",
    "        else:\n",
    "            # Position unchanged, update holdings value\n",
    "            if prev_position != 0:\n",
    "                # Update holdings based on price change\n",
    "                if prev_position > 0:  # Long position\n",
    "                    shares = prev_holdings / prev_price\n",
    "                    portfolio['holdings'].iloc[i] = shares * price\n",
    "                else:  # Short position\n",
    "                    shares = abs(prev_holdings / prev_price)\n",
    "                    portfolio['holdings'].iloc[i] = -shares * price\n",
    "            else:\n",
    "                portfolio['holdings'].iloc[i] = 0\n",
    "            \n",
    "            portfolio['cash'].iloc[i] = prev_cash\n",
    "        \n",
    "        # Update position\n",
    "        portfolio['position'].iloc[i] = new_position\n",
    "        \n",
    "        # Calculate portfolio value\n",
    "        portfolio['total'].iloc[i] = portfolio['cash'].iloc[i] + portfolio['holdings'].iloc[i]\n",
    "        \n",
    "        # Calculate returns\n",
    "        portfolio['returns'].iloc[i] = portfolio['total'].iloc[i] / portfolio['total'].iloc[i-1] - 1\n",
    "    \n",
    "    # Calculate performance metrics\n",
    "    portfolio['cumulative_returns'] = (1 + portfolio['returns']).cumprod() - 1\n",
    "    annual_return = portfolio['returns'].mean() * 252\n",
    "    annual_vol = portfolio['returns'].std() * np.sqrt(252)\n",
    "    sharpe_ratio = annual_return / annual_vol if annual_vol > 0 else 0\n",
    "    max_drawdown = (portfolio['total'] / portfolio['total'].cummax() - 1).min()\n",
    "    \n",
    "    # Store metrics\n",
    "    metrics = {\n",
    "        'annual_return': annual_return,\n",
    "        'annual_volatility': annual_vol,\n",
    "        'sharpe_ratio': sharpe_ratio,\n",
    "        'max_drawdown': max_drawdown,\n",
    "        'final_value': portfolio['total'].iloc[-1],\n",
    "        'total_return': portfolio['total'].iloc[-1] / initial_capital - 1\n",
    "    }\n",
    "    \n",
    "    return portfolio, metrics\n",
    "\n",
    "# Run backtest for each ticker\n",
    "backtest_results = {}\n",
    "\n",
    "for ticker in enhanced_data:\n",
    "    print(f\"\\nBacktesting strategies for {ticker}...\")\n",
    "    \n",
    "    data = enhanced_data[ticker]\n",
    "    \n",
    "    # Generate signals\n",
    "    base_signals = generate_sentiment_enhanced_signals(data)['base_signal']\n",
    "    enhanced_signals = generate_sentiment_enhanced_signals(data)['enhanced_signal']\n",
    "    \n",
    "    # Run backtests\n",
    "    base_portfolio, base_metrics = backtest_strategy(data, base_signals)\n",
    "    enhanced_portfolio, enhanced_metrics = backtest_strategy(data, enhanced_signals)\n",
    "    \n",
    "    # Store results\n",
    "    backtest_results[ticker] = {\n",
    "        'base': {\n",
    "            'portfolio': base_portfolio,\n",
    "            'metrics': base_metrics\n",
    "        },\n",
    "        'enhanced': {\n",
    "            'portfolio': enhanced_portfolio,\n",
    "            'metrics': enhanced_metrics\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    # Print performance comparison\n",
    "    print(f\"\\n{ticker} Performance Comparison:\")\n",
    "    print(f\"  Base Strategy:\")\n",
    "    print(f\"    Annual Return: {base_metrics['annual_return']:.2%}\")\n",
    "    print(f\"    Sharpe Ratio: {base_metrics['sharpe_ratio']:.2f}\")\n",
    "    print(f\"    Max Drawdown: {base_metrics['max_drawdown']:.2%}\")\n",
    "    print(f\"    Total Return: {base_metrics['total_return']:.2%}\")\n",
    "    print(f\"\\n  Enhanced Strategy (with Sentiment):\")\n",
    "    print(f\"    Annual Return: {enhanced_metrics['annual_return']:.2%}\")\n",
    "    print(f\"    Sharpe Ratio: {enhanced_metrics['sharpe_ratio']:.2f}\")\n",
    "    print(f\"    Max Drawdown: {enhanced_metrics['max_drawdown']:.2%}\")\n",
    "    print(f\"    Total Return: {enhanced_metrics['total_return']:.2%}\")\n",
    "    \n",
    "    # Plot equity curves\n",
    "    plt.figure(figsize=(14, 7))\n",
    "    plt.plot(base_portfolio.index, base_portfolio['total'], label='Base Strategy')\n",
    "    plt.plot(enhanced_portfolio.index, enhanced_portfolio['total'], label='Enhanced Strategy')\n",
    "    plt.title(f\"{ticker}: Equity Curve Comparison\")\n",
    "    plt.xlabel('Date')\n",
    "    plt.ylabel('Portfolio Value ($)')\n",
    "    plt.legend()\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a277a20",
   "metadata": {},
   "source": [
    "## 6. Feature Importance Analysis\n",
    "\n",
    "Finally, let's analyze the importance of alternative data features in predicting returns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d6d2962",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze feature importance\n",
    "feature_importance = {}\n",
    "\n",
    "for ticker in enhanced_data:\n",
    "    print(f\"\\nAnalyzing feature importance for {ticker}...\")\n",
    "    \n",
    "    data = enhanced_data[ticker].copy()\n",
    "    \n",
    "    # Calculate next day returns as target\n",
    "    data['next_return'] = data['return'].shift(-1)\n",
    "    \n",
    "    # Get feature importance\n",
    "    try:\n",
    "        importance = alt_data.create_feature_importance_analysis(data, target_col='next_return')\n",
    "        feature_importance[ticker] = importance\n",
    "        \n",
    "        # Plot top features\n",
    "        top_features = importance['top_features']\n",
    "        top_importances = [importance['importance'][importance['feature_names'].index(f)] for f in top_features]\n",
    "        \n",
    "        plt.figure(figsize=(12, 6))\n",
    "        y_pos = range(len(top_features))\n",
    "        plt.barh(y_pos, top_importances, align='center')\n",
    "        plt.yticks(y_pos, top_features)\n",
    "        plt.xlabel('Importance')\n",
    "        plt.title(f\"{ticker}: Feature Importance for Return Prediction\")\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "        \n",
    "        print(f\"  R² Score: {importance['r2_score']:.4f}\")\n",
    "        print(f\"  Top 5 features: {', '.join(top_features[:5])}\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"  Error analyzing feature importance: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aee7606d",
   "metadata": {},
   "source": [
    "## 7. Conclusion\n",
    "\n",
    "In this notebook, we've explored the integration of alternative data sources with traditional market data for enhanced signal generation in quantitative trading strategies. The key findings include:\n",
    "\n",
    "1. **Sentiment Impact**: News sentiment can provide additional signals that complement traditional price-based indicators.\n",
    "\n",
    "2. **Enhanced Performance**: Strategies incorporating sentiment data generally showed improved risk-adjusted returns compared to base strategies.\n",
    "\n",
    "3. **Feature Importance**: Several alternative data features ranked among the top predictors for future returns, demonstrating their potential value.\n",
    "\n",
    "### Further Research Opportunities\n",
    "\n",
    "- Integration of additional alternative data sources such as satellite imagery and web traffic\n",
    "- More sophisticated NLP techniques for sentiment analysis, including topic modeling and entity extraction\n",
    "- Exploration of non-linear relationships between sentiment and returns using advanced machine learning models\n",
    "- Investigation of sentiment lead/lag relationships with different asset classes and market regimes"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "quant_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
